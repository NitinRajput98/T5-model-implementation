{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJzDxo7aIpzY",
    "papermill": {
     "duration": 0.043911,
     "end_time": "2020-11-27T08:04:45.782189",
     "exception": false,
     "start_time": "2020-11-27T08:04:45.738278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# T5 for Sentiment Span Extraction\n",
    "\n",
    "\n",
    "## T5 Overview\n",
    "\n",
    "T5 is a recently released encoder-decoder model that reaches SOTA results by solving NLP problems with a text-to-text approach. This is where text is used as both an input and an output for solving all types of tasks. This was introduced in the recent paper, *Exploring the Limits of Transfer Learning with a\n",
    "Unified Text-to-Text Transformer* ([paper](https://arxiv.org/pdf/1910.10683.pdf)). I've been deeply interested in this model the moment I read about it.\n",
    "\n",
    "I believe that the combination of text-to-text as a universal interface for NLP tasks paired with multi-task learning (single model learning multiple tasks) will have a huge impact on how NLP deep learning is applied in practice.\n",
    "\n",
    "In this presentation I aim to give a brief overview of T5, explain some of its implications for NLP in industry, and demonstrate how it can be used for sentiment span extraction on tweets. I hope this material helps you guys use T5 for your own purposes!\n",
    "\n",
    "\n",
    "## Key points from T5 paper\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=15XQ-H7IdT3DVtbL7fgwYIm08OYWbB8VZ\" width=\"700\" height=\"300\" />\n",
    "\n",
    "1. **Treats each NLP problem as a “text-to-text” problem** - input: text, output: text\n",
    "\n",
    "2. **Unified approach for NLP Deep Learning** - Since the task is reflected purely in the text input and output, you can use the same model, objective, training procedure, and decoding process to ANY task. Above framework can be used for any task - show Q&A, summarization, etc.\n",
    "\n",
    "3. **Multiple NLP tasks can live in the same model** - E.g. Q&A, semantic similarity, etc. However, there is a problem called *task interference* where good results on one task can also mean worse results on another task. E.g., a good summarizer may be bad at Q&A and vice versa. All the tasks above can live in the same model, which is how it works with the released T5 models (t5-small, t5-base, etc.)\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1-1SXVF78l3EbsuTeDUEv0hUvgfMIch3f\" width=\"700\" height=\"165\" />\n",
    "\n",
    "4. **New dataset: “Colossal Clean Crawled Corpus” (C4)** - a dataset consisting of ~750GB of clean English text scraped from the web. Created with a month of data from the Common Crawl corpus cleaned with a set of heuristics to filter out \"unhelpful\" text (e.g. offensive language, placeholder text, source code). This is a lot larger than the 13GB of data used for BERT, and 126GB of data used for XLNet.\n",
    "\n",
    "\n",
    "5. **A simple denoising training objective was used for pretraining** Basically, masked language modelling but while considering contiguous masks as a single “span” to predict, and where the final prediction is an actual text sequence containing the answers (represented by “sentinel tokens”). This was compared to a language modeling pre-training objective and results consistently improved.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1iPG7UxZPvy6c2iwixQXYetpTzcHiKDuW\" width=\"500\" height=\"200\" />\n",
    "\n",
    "6. **Full encoder-decoder transformer architecture is used** - this is in contrast to previous architectures that were either encoder based (e.g. BERT), or decoder based (e.g. GPT-2). This was found effective for both generation & classification tasks.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1tUxL_os-pn8JTBSCY6l-9rQI0EMPC5Zz\" width=\"400\" height=\"500\" />\n",
    "\n",
    "\n",
    "## Key insight\n",
    "\n",
    "Multiple NLP tasks can be learned by a single model since every NLP problem can be represented in a unified way - as a controllable text generation problem.\n",
    "\n",
    "## Expected impact\n",
    "\n",
    "Increased adoption of multi-task models like T5 due to SOTA accuracy paired with lower time, compute, & storage costs for both deployments and experiments in NLP.\n",
    "\n",
    "## T5 for Sentiment Span Extraction (PyTorch)\n",
    "\n",
    "1. This is a dataset from an existing Kaggle [competition](https://www.kaggle.com/c/tweet-sentiment-extraction/data) - Tweet Sentiment Extraction\n",
    "2. Most of the existing model implementations use some sort of token classification task\n",
    "  - The index of the beginning and ending tokens are predicted and use to *extract* the span\n",
    "\n",
    "3. T5 is an approach that is purely *generative*, like a classic language modelling task\n",
    "  - This is similar to abstractize summarization, translation, and overall text generation\n",
    "  - For our data, the span is not *extracted* by predicting indices, but by generating the span from scratch\n",
    "\n",
    "## Let's get started!\n",
    "\n",
    "-----------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNNTPDxGdbwV",
    "papermill": {
     "duration": 0.040059,
     "end_time": "2020-11-27T08:04:45.863343",
     "exception": false,
     "start_time": "2020-11-27T08:04:45.823284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Related links\n",
    "1. [T5 Paper](https://arxiv.org/pdf/1910.10683.pdf) - Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\n",
    "2. [T5 Implementation on PyTorch](https://github.com/huggingface/transformers/blob/455c6390938a5c737fa63e78396cedae41e4e87e/src/transformers/modeling_t5.py) by HuggingFace\n",
    "3. [T5 Exploration Notebook](https://colab.research.google.com/drive/1dYqSqq4OCDV0nN3gkagjqXoWX8ZqrE-7?usp=sharing) demonstrating how to use t5-base for summarization and Q&A\n",
    "4. [SQuAD Dataset](https://rajpurkar.github.io/SQuAD-explorer/) for extractive Q&A\n",
    "5. [Tweet Sentiment Extraction](https://www.kaggle.com/c/tweet-sentiment-extraction) (Kaggle Competition)\n",
    "6. [Bert Base Uncased for Sentiment Span Extraction (Token Classification)](https://www.kaggle.com/enzoamp/commented-bert-base-uncased-using-pytorch/comments) (Commented version of Abhishek Thakur's solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghUVyHh8Hhf0",
    "papermill": {
     "duration": 0.039253,
     "end_time": "2020-11-27T08:04:45.943377",
     "exception": false,
     "start_time": "2020-11-27T08:04:45.904124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installation\n",
    "\n",
    "Installing the [transformers](https://github.com/huggingface/transformers) + [Pytorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning) libraries. The rest of the required packages are already installed in Google Colab by default.\n",
    "\n",
    "I'd describe PyTorch Lightning as a PyTorch wrapper that simplifies the process of writing PyTorch code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:04:46.031186Z",
     "iopub.status.busy": "2020-11-27T08:04:46.030357Z",
     "iopub.status.idle": "2020-11-27T08:05:06.653061Z",
     "shell.execute_reply": "2020-11-27T08:05:06.652435Z"
    },
    "id": "k9BjtREAMd5A",
    "outputId": "010b3f8e-c563-466c-b6c1-9b8429567f95",
    "papermill": {
     "duration": 20.669579,
     "end_time": "2020-11-27T08:05:06.653187",
     "exception": false,
     "start_time": "2020-11-27T08:04:45.983608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (2.9.0)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.43)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.23.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2020.4.4)\r\n",
      "Requirement already satisfied: tokenizers==0.7.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.7.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.10)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.45.0)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from transformers) (0.1.86)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers) (1.18.1)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.9)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.24.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.4.5.1)\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.2.4 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Collecting pytorch_lightning==0.9.0\r\n",
      "  Downloading pytorch_lightning-0.9.0-py3-none-any.whl (408 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 408 kB 4.1 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==0.9.0) (5.3.1)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==0.9.0) (20.1)\r\n",
      "Requirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==0.9.0) (1.5.0)\r\n",
      "Requirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==0.9.0) (0.18.2)\r\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==0.9.0) (4.45.0)\r\n",
      "Collecting tensorboard==2.2.0\r\n",
      "  Downloading tensorboard-2.2.0-py3-none-any.whl (2.8 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 42.1 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.4 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==0.9.0) (1.18.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->pytorch_lightning==0.9.0) (2.4.7)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->pytorch_lightning==0.9.0) (1.14.0)\r\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\r\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 779 kB 24.8 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch_lightning==0.9.0) (3.2.1)\r\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch_lightning==0.9.0) (0.34.2)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch_lightning==0.9.0) (1.28.1)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch_lightning==0.9.0) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch_lightning==0.9.0) (2.23.0)\r\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch_lightning==0.9.0) (3.11.4)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch_lightning==0.9.0) (1.14.0)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch_lightning==0.9.0) (0.9.0)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch_lightning==0.9.0) (1.0.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch_lightning==0.9.0) (0.4.1)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0->pytorch_lightning==0.9.0) (1.24.3)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0->pytorch_lightning==0.9.0) (2.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0->pytorch_lightning==0.9.0) (2020.4.5.1)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0->pytorch_lightning==0.9.0) (3.0.4)\r\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch_lightning==0.9.0) (4.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch_lightning==0.9.0) (0.2.7)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch_lightning==0.9.0) (3.1.1)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.2.0->pytorch_lightning==0.9.0) (1.2.0)\r\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch_lightning==0.9.0) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.2.0->pytorch_lightning==0.9.0) (3.0.1)\r\n",
      "\u001b[31mERROR: tensorflow 2.1.0 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 2.2.0 which is incompatible.\u001b[0m\r\n",
      "Installing collected packages: tensorboard-plugin-wit, tensorboard, pytorch-lightning\r\n",
      "  Attempting uninstall: tensorboard\r\n",
      "    Found existing installation: tensorboard 2.1.1\r\n",
      "    Uninstalling tensorboard-2.1.1:\r\n",
      "      Successfully uninstalled tensorboard-2.1.1\r\n",
      "Successfully installed pytorch-lightning-0.9.0 tensorboard-2.2.0 tensorboard-plugin-wit-1.7.0\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.2.4 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "# !pip pytorch_lightning==0.9.0\n",
    "# !pip install pytorch-lightning\n",
    "!pip install pytorch_lightning==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:06.767677Z",
     "iopub.status.busy": "2020-11-27T08:05:06.766601Z",
     "iopub.status.idle": "2020-11-27T08:05:07.471932Z",
     "shell.execute_reply": "2020-11-27T08:05:07.471294Z"
    },
    "papermill": {
     "duration": 0.76475,
     "end_time": "2020-11-27T08:05:07.472114",
     "exception": false,
     "start_time": "2020-11-27T08:05:06.707364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test.csv  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls ../input/tweet-sentiment-extraction/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7P5C7xGaMcUM",
    "papermill": {
     "duration": 0.053312,
     "end_time": "2020-11-27T08:05:07.578120",
     "exception": false,
     "start_time": "2020-11-27T08:05:07.524808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFegh1JsvDjQ",
    "papermill": {
     "duration": 0.052745,
     "end_time": "2020-11-27T08:05:07.684739",
     "exception": false,
     "start_time": "2020-11-27T08:05:07.631994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:07.795527Z",
     "iopub.status.busy": "2020-11-27T08:05:07.794515Z",
     "iopub.status.idle": "2020-11-27T08:05:08.775969Z",
     "shell.execute_reply": "2020-11-27T08:05:08.774988Z"
    },
    "id": "aSKRffoaJYKb",
    "papermill": {
     "duration": 1.039714,
     "end_time": "2020-11-27T08:05:08.776101",
     "exception": false,
     "start_time": "2020-11-27T08:05:07.736387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:08.886699Z",
     "iopub.status.busy": "2020-11-27T08:05:08.885673Z",
     "iopub.status.idle": "2020-11-27T08:05:09.003094Z",
     "shell.execute_reply": "2020-11-27T08:05:09.002232Z"
    },
    "id": "auRxG9amJYKw",
    "papermill": {
     "duration": 0.175245,
     "end_time": "2020-11-27T08:05:09.003219",
     "exception": false,
     "start_time": "2020-11-27T08:05:08.827974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Row 314 of train set is nan\n",
    "train = pd.read_csv('../input/tweet-sentiment-extraction/train.csv').dropna()#.head(1000)\n",
    "test = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')#.head(1000)\n",
    "\n",
    "# Set random 13% as the validation set (make validation set similar in size to test set)\n",
    "train, val = train_test_split(train, test_size=0.13, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:09.115767Z",
     "iopub.status.busy": "2020-11-27T08:05:09.114270Z",
     "iopub.status.idle": "2020-11-27T08:05:09.118640Z",
     "shell.execute_reply": "2020-11-27T08:05:09.119140Z"
    },
    "id": "eAyvcozH5kbN",
    "outputId": "127e0561-9033-4bb9-ff78-79141c8b0591",
    "papermill": {
     "duration": 0.064131,
     "end_time": "2020-11-27T08:05:09.119265",
     "exception": false,
     "start_time": "2020-11-27T08:05:09.055134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23907, 4), (3534, 3), (3573, 4))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8V06zveCAxTW",
    "papermill": {
     "duration": 0.052363,
     "end_time": "2020-11-27T08:05:09.223838",
     "exception": false,
     "start_time": "2020-11-27T08:05:09.171475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Confirm that the train set doesn't have any overlaps with the test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:09.350394Z",
     "iopub.status.busy": "2020-11-27T08:05:09.348915Z",
     "iopub.status.idle": "2020-11-27T08:05:09.352789Z",
     "shell.execute_reply": "2020-11-27T08:05:09.353321Z"
    },
    "id": "KcWsXdQ_AcBP",
    "outputId": "71ff2ab5-3828-4f5e-bd36-6b2d996c8496",
    "papermill": {
     "duration": 0.074913,
     "end_time": "2020-11-27T08:05:09.353480",
     "exception": false,
     "start_time": "2020-11-27T08:05:09.278567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(set(), set())"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test.textID.values).intersection(train.textID.values), set(val.textID.values).intersection(train.textID.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:09.477862Z",
     "iopub.status.busy": "2020-11-27T08:05:09.476842Z",
     "iopub.status.idle": "2020-11-27T08:05:09.480584Z",
     "shell.execute_reply": "2020-11-27T08:05:09.481145Z"
    },
    "id": "Sb1CYxJPJYKz",
    "outputId": "f3ef9037-e3bc-4cd6-b440-ebf5603056f7",
    "papermill": {
     "duration": 0.075291,
     "end_time": "2020-11-27T08:05:09.481290",
     "exception": false,
     "start_time": "2020-11-27T08:05:09.405999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           textID                                               text  \\\n",
       " 17391  a4ccd2c1a9   How did we just get paid and still be broke a...   \n",
       " 10951  5c3d9c52f6  i no i no bt i had only been a gamer for like ...   \n",
       " 19109  05bc7a77ef  I love when my ipod shuffles so all the good s...   \n",
       " 16873  cfb49dff56   no i mean 2moz. I`m workin` 7-1 in a bakers t...   \n",
       " 22461  f497495e23  Lovely walk this morning with the missus; driz...   \n",
       " \n",
       "                                            selected_text sentiment  \n",
       " 17391                                    broke as hell?!  negative  \n",
       " 10951                                               luvd  positive  \n",
       " 19109                                               love  positive  \n",
       " 16873  no i mean 2moz. I`m workin` 7-1 in a bakers th...   neutral  \n",
       " 22461  Lovely walk this morning with the missus; driz...  positive  ,\n",
       "        textID                                               text sentiment\n",
       " 0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n",
       " 1  96d74cb729   Shanghai is also really exciting (precisely -...  positive\n",
       " 2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative\n",
       " 3  01082688c6                                        happy bday!  positive\n",
       " 4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive,\n",
       "            textID                                               text  \\\n",
       " 1589   6c5505a37c                    Enjoy! Family trumps everything   \n",
       " 10414  126b1e6a22   --of them kinda turns me off of it all.  And ...   \n",
       " 6562   5bc4e623c4  Clive it`s my birthday pat me  http://apps.fac...   \n",
       " 2603   984d753104                                       congrats hey   \n",
       " 4004   8a79072ca2                                         is texting   \n",
       " \n",
       "                          selected_text sentiment  \n",
       " 1589   Enjoy! Family trumps everything  positive  \n",
       " 10414               kinda turns me off  negative  \n",
       " 6562     Clive it`s my birthday pat me   neutral  \n",
       " 2603                          congrats  positive  \n",
       " 4004                        is texting   neutral  )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(), test.head(), val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:09.594963Z",
     "iopub.status.busy": "2020-11-27T08:05:09.594076Z",
     "iopub.status.idle": "2020-11-27T08:05:09.597625Z",
     "shell.execute_reply": "2020-11-27T08:05:09.598122Z"
    },
    "id": "s24C6B08j4Fz",
    "outputId": "8f28ccdb-64d2-4933-b2d4-ca5778a071d6",
    "papermill": {
     "duration": 0.063692,
     "end_time": "2020-11-27T08:05:09.598261",
     "exception": false,
     "start_time": "2020-11-27T08:05:09.534569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['textID', 'text', 'selected_text', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNadgQMdvPOq",
    "papermill": {
     "duration": 0.052995,
     "end_time": "2020-11-27T08:05:09.705707",
     "exception": false,
     "start_time": "2020-11-27T08:05:09.652712",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Checking out how the data looks\n",
    "\n",
    "My biggest concern is that sometimes the span is a single word like \"afraid\", but then sometimes it's a whole phrase, like \"jip i have a good one\". I suspect that this variation may be harder to model with deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:09.826150Z",
     "iopub.status.busy": "2020-11-27T08:05:09.824330Z",
     "iopub.status.idle": "2020-11-27T08:05:09.831366Z",
     "shell.execute_reply": "2020-11-27T08:05:09.830362Z"
    },
    "id": "Tu5sPDosjldF",
    "outputId": "bfd46549-31d5-41d0-e9c9-97006866698b",
    "papermill": {
     "duration": 0.071438,
     "end_time": "2020-11-27T08:05:09.831541",
     "exception": false,
     "start_time": "2020-11-27T08:05:09.760103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment: negative tweet:  How did we just get paid and still be broke as hell?! No shopping spree for me today\n",
      "sentiment: positive tweet: i no i no bt i had only been a gamer for like 2 years when i made that attempt  lol yea i luvd F1 to an extent \n",
      "sentiment: positive tweet: I love when my ipod shuffles so all the good songs are all together\n",
      "sentiment: neutral tweet:  no i mean 2moz. I`m workin` 7-1 in a bakers then 6-4 later in a pub\n",
      "sentiment: positive tweet: Lovely walk this morning with the missus; drizzle didn`t matter\n",
      "sentiment: neutral tweet:  , just dont understand what`s it got to do with me. I`m just a nice girl\n",
      "sentiment: negative tweet: getting bored of walking up and down the stairs\n",
      "sentiment: positive tweet:  have your own style. it just might work.\n",
      "sentiment: negative tweet: fighting with mum on mothers day\n",
      "sentiment: neutral tweet:  & I got too much work to do\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "for a,b,_ in zip(train.sentiment.values[:10], train.text.values[:10], train.selected_text.values[:10]):\n",
    "    print(\"sentiment:\", a, \"tweet:\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:09.947441Z",
     "iopub.status.busy": "2020-11-27T08:05:09.946480Z",
     "iopub.status.idle": "2020-11-27T08:05:09.951347Z",
     "shell.execute_reply": "2020-11-27T08:05:09.951834Z"
    },
    "id": "Eym7h9yTkG2-",
    "outputId": "e9411b6d-fa76-42fa-ed6a-62b5d649078c",
    "papermill": {
     "duration": 0.066976,
     "end_time": "2020-11-27T08:05:09.951970",
     "exception": false,
     "start_time": "2020-11-27T08:05:09.884994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broke as hell?!\n",
      "luvd\n",
      "love\n",
      "no i mean 2moz. I`m workin` 7-1 in a bakers then 6-4 later in a pub\n",
      "Lovely walk this morning with the missus; drizzle didn`t matter\n",
      ", just dont understand what`s it got to do with me. I`m just a nice girl\n",
      "getting bored of walking up and down the stairs\n",
      "it just might work.\n",
      "fighting\n",
      "I got too much work to do\n"
     ]
    }
   ],
   "source": [
    "# Target (what we're trying to predict)\n",
    "for _,_,c in zip(train.sentiment.values[:10], train.text.values[:10], train.selected_text.values[:10]):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seQYpn4dvW1q",
    "papermill": {
     "duration": 0.056004,
     "end_time": "2020-11-27T08:05:10.063232",
     "exception": false,
     "start_time": "2020-11-27T08:05:10.007228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's see the GPU we get from Colab.\n",
    "\n",
    "If you're lucky, you get a P100, but you will typically get a K80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:10.181836Z",
     "iopub.status.busy": "2020-11-27T08:05:10.177780Z",
     "iopub.status.idle": "2020-11-27T08:05:11.499512Z",
     "shell.execute_reply": "2020-11-27T08:05:11.498556Z"
    },
    "id": "6krpC4qiMcJ5",
    "outputId": "6ce56d12-1132-449d-a6ea-f27f0419fc1c",
    "papermill": {
     "duration": 1.381864,
     "end_time": "2020-11-27T08:05:11.499669",
     "exception": false,
     "start_time": "2020-11-27T08:05:10.117805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 27 08:05:11 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# Checking out the GPU we have access to\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:11.615154Z",
     "iopub.status.busy": "2020-11-27T08:05:11.614490Z",
     "iopub.status.idle": "2020-11-27T08:05:13.466663Z",
     "shell.execute_reply": "2020-11-27T08:05:13.466118Z"
    },
    "papermill": {
     "duration": 1.911595,
     "end_time": "2020-11-27T08:05:13.466799",
     "exception": false,
     "start_time": "2020-11-27T08:05:11.555204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzDzPYzEJYK4",
    "papermill": {
     "duration": 0.055573,
     "end_time": "2020-11-27T08:05:13.578701",
     "exception": false,
     "start_time": "2020-11-27T08:05:13.523128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Format data to input text Q&A format\n",
    "\n",
    "For the T5 model, I decided to build on top of the existing Q&A task already learned by T5 since the nature of Q&A based on the SQuAD dataset is **extractive** in nature.\n",
    "\n",
    "In other words, utilizing the Q&A task's text formatting should theoretically allow us to utilize T5's existing knowledge of extracting spans from an input text, which is exactly what we want to do for this sentiment span extraction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:13.720649Z",
     "iopub.status.busy": "2020-11-27T08:05:13.719628Z",
     "iopub.status.idle": "2020-11-27T08:05:13.737486Z",
     "shell.execute_reply": "2020-11-27T08:05:13.736941Z"
    },
    "id": "bka57iFhJYK5",
    "outputId": "70b656c1-1b6b-4ccd-9562-f8935de2df50",
    "papermill": {
     "duration": 0.103147,
     "end_time": "2020-11-27T08:05:13.737623",
     "exception": false,
     "start_time": "2020-11-27T08:05:13.634476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for NaNs\n",
    "train.isna().sum().sum(), test.isna().sum().sum(), val.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:13.867334Z",
     "iopub.status.busy": "2020-11-27T08:05:13.866306Z",
     "iopub.status.idle": "2020-11-27T08:05:13.921592Z",
     "shell.execute_reply": "2020-11-27T08:05:13.920991Z"
    },
    "id": "4VQaCWw5JYK-",
    "papermill": {
     "duration": 0.123552,
     "end_time": "2020-11-27T08:05:13.921700",
     "exception": false,
     "start_time": "2020-11-27T08:05:13.798148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Append EOS token to target text\n",
    "# This is the standard format for T5 targets\n",
    "# More info in transformers docs: https://huggingface.co/transformers/model_doc/t5.html\n",
    "train['selected_text'] = train['selected_text'] + ' </s>'\n",
    "val['selected_text'] = val['selected_text'] + ' </s>'\n",
    "\n",
    "# Apply Q&A structure\n",
    "# From Appendix D in the T5 paper\n",
    "processed_input_train = (\"question: \" + train.sentiment + \" context: \" + train.text)\n",
    "processed_input_test = (\"question: \" + test.sentiment + \" context: \" + test.text)\n",
    "processed_input_val = (\"question: \" + val.sentiment + \" context: \" + val.text)\n",
    "\n",
    "# Save data as string separated by \\n (new line)\n",
    "processed_input_str_train = '\\n'.join(processed_input_train.values.tolist())\n",
    "processed_input_str_test = '\\n'.join(processed_input_test.values.tolist())\n",
    "selected_text_str_train = '\\n'.join(train['selected_text'].values.tolist())\n",
    "processed_input_str_val = '\\n'.join(processed_input_val.values.tolist()[:500])\n",
    "selected_text_str_val = '\\n'.join(val['selected_text'].values.tolist()[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:14.055202Z",
     "iopub.status.busy": "2020-11-27T08:05:14.052621Z",
     "iopub.status.idle": "2020-11-27T08:05:14.058665Z",
     "shell.execute_reply": "2020-11-27T08:05:14.059168Z"
    },
    "id": "IwcTHBxsJYLF",
    "outputId": "915e18f7-0400-47df-f170-df987421adeb",
    "papermill": {
     "duration": 0.07192,
     "end_time": "2020-11-27T08:05:14.059297",
     "exception": false,
     "start_time": "2020-11-27T08:05:13.987377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('question: neutral context:  I`d have responded, if I were going',\n",
       " 'I`d have responded, if I were going </s>')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_input_train[0], train['selected_text'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:14.179675Z",
     "iopub.status.busy": "2020-11-27T08:05:14.178778Z",
     "iopub.status.idle": "2020-11-27T08:05:14.182160Z",
     "shell.execute_reply": "2020-11-27T08:05:14.182740Z"
    },
    "id": "QxufgYo7JYLJ",
    "outputId": "01e5ae67-bdd0-4ff2-9ceb-38f38ac50c2c",
    "papermill": {
     "duration": 0.06711,
     "end_time": "2020-11-27T08:05:14.182897",
     "exception": false,
     "start_time": "2020-11-27T08:05:14.115787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'question: neutral context: Last session of the day  http://twitpic.com/67ezh'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_input_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLtuUUYFJYLM",
    "papermill": {
     "duration": 0.058559,
     "end_time": "2020-11-27T08:05:14.299306",
     "exception": false,
     "start_time": "2020-11-27T08:05:14.240747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save input files\n",
    "\n",
    "We save the inputs as text files since our DataLoader class takes in data in this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:14.421685Z",
     "iopub.status.busy": "2020-11-27T08:05:14.420709Z",
     "iopub.status.idle": "2020-11-27T08:05:14.430204Z",
     "shell.execute_reply": "2020-11-27T08:05:14.429556Z"
    },
    "id": "l-8oZk-pJYLN",
    "papermill": {
     "duration": 0.073599,
     "end_time": "2020-11-27T08:05:14.430312",
     "exception": false,
     "start_time": "2020-11-27T08:05:14.356713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save source files\n",
    "\n",
    "with open('train.source', 'w') as f:\n",
    "    f.write(processed_input_str_train)\n",
    "    \n",
    "# Making dev similar in this case\n",
    "with open('test.source', 'w') as f:\n",
    "    f.write(processed_input_str_test)\n",
    "    \n",
    "with open('val.source', 'w') as f:\n",
    "    f.write(processed_input_str_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:14.551148Z",
     "iopub.status.busy": "2020-11-27T08:05:14.550335Z",
     "iopub.status.idle": "2020-11-27T08:05:15.248475Z",
     "shell.execute_reply": "2020-11-27T08:05:15.247927Z"
    },
    "id": "aRpwgJE8JYLQ",
    "outputId": "de1e4d11-a289-4b8f-871e-b81e369aaa33",
    "papermill": {
     "duration": 0.760505,
     "end_time": "2020-11-27T08:05:15.248636",
     "exception": false,
     "start_time": "2020-11-27T08:05:14.488131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: negative context:  How did we just get paid and still be broke as hell?! No shopping spree for me today\r\n",
      "question: positive context: i no i no bt i had only been a gamer for like 2 years when i made that attempt  lol yea i luvd F1 to an extent \r\n",
      "question: positive context: I love when my ipod shuffles so all the good songs are all together\r\n",
      "question: neutral context:  no i mean 2moz. I`m workin` 7-1 in a bakers then 6-4 later in a pub\r\n",
      "question: positive context: Lovely walk this morning with the missus; drizzle didn`t matter\r\n",
      "question: neutral context:  , just dont understand what`s it got to do with me. I`m just a nice girl\r\n",
      "question: negative context: getting bored of walking up and down the stairs\r\n",
      "question: positive context:  have your own style. it just might work.\r\n",
      "question: negative context: fighting with mum on mothers day\r\n",
      "question: neutral context:  & I got too much work to do\r\n"
     ]
    }
   ],
   "source": [
    "!head train.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:15.376579Z",
     "iopub.status.busy": "2020-11-27T08:05:15.375615Z",
     "iopub.status.idle": "2020-11-27T08:05:16.075379Z",
     "shell.execute_reply": "2020-11-27T08:05:16.075937Z"
    },
    "id": "AKG0fleVJYLV",
    "outputId": "61506cf0-e053-4d06-83a0-00ce41916e1c",
    "papermill": {
     "duration": 0.766929,
     "end_time": "2020-11-27T08:05:16.076097",
     "exception": false,
     "start_time": "2020-11-27T08:05:15.309168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: neutral context: Last session of the day  http://twitpic.com/67ezh\r\n",
      "question: positive context:  Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).\r\n",
      "question: negative context: Recession hit Veronique Branquinho, she has to quit her company, such a shame!\r\n",
      "question: positive context:  happy bday!\r\n",
      "question: positive context:  http://twitpic.com/4w75p - I like it!!\r\n",
      "question: positive context:  that`s great!! weee!! visitors!\r\n",
      "question: negative context: I THINK EVERYONE HATES ME ON HERE   lol\r\n",
      "question: negative context:  soooooo wish i could, but im in school and myspace is completely blocked\r\n",
      "question: neutral context:  and within a short time of the last clue all of them\r\n",
      "question: neutral context:  What did you get?  My day is alright.. haven`t done anything yet. leaving soon to my stepsister though!\r\n"
     ]
    }
   ],
   "source": [
    "!head test.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:16.207589Z",
     "iopub.status.busy": "2020-11-27T08:05:16.206399Z",
     "iopub.status.idle": "2020-11-27T08:05:16.903486Z",
     "shell.execute_reply": "2020-11-27T08:05:16.902867Z"
    },
    "id": "xEdikCY9JYLY",
    "outputId": "8d906c29-8e6e-4d9b-ba55-427db5f4644c",
    "papermill": {
     "duration": 0.768123,
     "end_time": "2020-11-27T08:05:16.903680",
     "exception": false,
     "start_time": "2020-11-27T08:05:16.135557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: positive context:  Enjoy! Family trumps everything\r\n",
      "question: negative context:  --of them kinda turns me off of it all.  And then I buy more of them and dig a deeper hole, etc. ;;\r\n",
      "question: neutral context: Clive it`s my birthday pat me  http://apps.facebook.com/dogbook/profile/view/6386106\r\n",
      "question: positive context:  congrats hey\r\n",
      "question: neutral context: is texting\r\n",
      "question: neutral context:  Do you have any idea when the (not so) patient fans will see some teaser pics of you all in costume?\r\n",
      "question: neutral context:  Tell him where...\r\n",
      "question: negative context:  Ooooh, I`m jealous  I might try and get some for the saturday but I have an exam on the monday that Im gonna fail\r\n",
      "question: neutral context:  OHSHNAPSSS. is she pissed at blair as usual ? hahah. & yeeeah, i bake cookies\r\n",
      "question: neutral context: wee. done with advance audit paper\r\n"
     ]
    }
   ],
   "source": [
    "!head val.source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pQJfXOkJYLb",
    "papermill": {
     "duration": 0.059588,
     "end_time": "2020-11-27T08:05:17.027515",
     "exception": false,
     "start_time": "2020-11-27T08:05:16.967927",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save target file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:17.153578Z",
     "iopub.status.busy": "2020-11-27T08:05:17.152555Z",
     "iopub.status.idle": "2020-11-27T08:05:17.156789Z",
     "shell.execute_reply": "2020-11-27T08:05:17.156174Z"
    },
    "id": "Ip_sb89HJYLb",
    "papermill": {
     "duration": 0.069769,
     "end_time": "2020-11-27T08:05:17.156899",
     "exception": false,
     "start_time": "2020-11-27T08:05:17.087130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('train.target', 'w') as f:\n",
    "    f.write(selected_text_str_train)\n",
    "    \n",
    "with open('val.target', 'w') as f:\n",
    "    f.write(selected_text_str_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:17.290729Z",
     "iopub.status.busy": "2020-11-27T08:05:17.289669Z",
     "iopub.status.idle": "2020-11-27T08:05:18.004342Z",
     "shell.execute_reply": "2020-11-27T08:05:18.003734Z"
    },
    "id": "fjx-bSx2JYLg",
    "outputId": "c997a69b-af62-4d9a-e25a-1040ca5a9b63",
    "papermill": {
     "duration": 0.786389,
     "end_time": "2020-11-27T08:05:18.004463",
     "exception": false,
     "start_time": "2020-11-27T08:05:17.218074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broke as hell?! </s>\r\n",
      "luvd </s>\r\n",
      "love </s>\r\n",
      "no i mean 2moz. I`m workin` 7-1 in a bakers then 6-4 later in a pub </s>\r\n",
      "Lovely walk this morning with the missus; drizzle didn`t matter </s>\r\n",
      ", just dont understand what`s it got to do with me. I`m just a nice girl </s>\r\n",
      "getting bored of walking up and down the stairs </s>\r\n",
      "it just might work. </s>\r\n",
      "fighting </s>\r\n",
      "I got too much work to do </s>\r\n"
     ]
    }
   ],
   "source": [
    "!head train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:18.137667Z",
     "iopub.status.busy": "2020-11-27T08:05:18.133471Z",
     "iopub.status.idle": "2020-11-27T08:05:18.836239Z",
     "shell.execute_reply": "2020-11-27T08:05:18.835244Z"
    },
    "id": "WU94HdcVJYLl",
    "outputId": "52351c82-7506-4e3a-a4c8-966c42daeac1",
    "papermill": {
     "duration": 0.768833,
     "end_time": "2020-11-27T08:05:18.836368",
     "exception": false,
     "start_time": "2020-11-27T08:05:18.067535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enjoy! Family trumps everything </s>\r\n",
      "kinda turns me off </s>\r\n",
      "Clive it`s my birthday pat me </s>\r\n",
      "congrats </s>\r\n",
      "is texting </s>\r\n",
      "Do you have any idea when the (not so) patient fans will see some teaser pics of you all in costume? </s>\r\n",
      "Tell him where... </s>\r\n",
      "t I have an exam on the monday that Im gonna fail </s>\r\n",
      "OHSHNAPSSS. is she pissed at blair as usual ? hahah. & yeeeah, i bake cookies </s>\r\n",
      "wee. done with advance audit paper </s>\r\n"
     ]
    }
   ],
   "source": [
    "!head val.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:18.969588Z",
     "iopub.status.busy": "2020-11-27T08:05:18.965230Z",
     "iopub.status.idle": "2020-11-27T08:05:19.663866Z",
     "shell.execute_reply": "2020-11-27T08:05:19.663299Z"
    },
    "id": "CwmOitjOJYLo",
    "outputId": "028f32ee-20e9-457b-c586-7a6f33ed7b1f",
    "papermill": {
     "duration": 0.765635,
     "end_time": "2020-11-27T08:05:19.663984",
     "exception": false,
     "start_time": "2020-11-27T08:05:18.898349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  train.source  val.source\r\n",
      "test.source         train.target  val.target\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZORta1ZJYLq",
    "papermill": {
     "duration": 0.061814,
     "end_time": "2020-11-27T08:05:19.788163",
     "exception": false,
     "start_time": "2020-11-27T08:05:19.726349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preparing the T5 Dataset\n",
    "\n",
    "Based on this summarization example from [transformers](https://github.com/huggingface/transformers/blob/master/examples/summarization/bart/finetune.py), which is compatible for both BART and T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:19.940871Z",
     "iopub.status.busy": "2020-11-27T08:05:19.931325Z",
     "iopub.status.idle": "2020-11-27T08:05:25.884426Z",
     "shell.execute_reply": "2020-11-27T08:05:25.883188Z"
    },
    "id": "bzJjYWOtJYLq",
    "papermill": {
     "duration": 6.034494,
     "end_time": "2020-11-27T08:05:25.884600",
     "exception": false,
     "start_time": "2020-11-27T08:05:19.850106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from transformers.tokenization_utils import trim_batch\n",
    "\n",
    "\n",
    "def encode_file(tokenizer, data_path, max_length, pad_to_max_length=True, return_tensors=\"pt\"):\n",
    "    \"\"\"\n",
    "    This function reads the text files that we prepared and returns them in tokenized form.\n",
    "\n",
    "    Actually tokenizer.batch_encode_plus returns these as a list of dictionaries where \n",
    "    each dictionary contains the word piece indices among other relevant inputs for training & inference\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    with open(data_path, \"r\") as f:\n",
    "        for text in f.readlines():\n",
    "            tokenized = tokenizer.batch_encode_plus(\n",
    "                [text], max_length=max_length, pad_to_max_length=pad_to_max_length, return_tensors=return_tensors,\n",
    "            )\n",
    "            examples.append(tokenized)\n",
    "    return examples\n",
    "\n",
    "\n",
    "class T5Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    This is the T5 dataset that can read our train, test, and dev files separately\n",
    "\n",
    "    This was patterned after the SummarizationDataset from the `transformer` library's summarization example (compatible with T5)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        data_dir=\"../working/\",\n",
    "        type_path=\"train\",\n",
    "        max_source_length=1024,\n",
    "        max_target_length=56,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Store the tokenizer\n",
    "        self.tokenizer = tokenizer\n",
    "        self.type_path = type_path\n",
    "        # Read the source and target files for the type of file (train, test, or val)\n",
    "        self.source = encode_file(tokenizer, os.path.join(data_dir, type_path + \".source\"), max_source_length)\n",
    "        self.target = None\n",
    "        if self.type_path != \"test\":\n",
    "            self.target = encode_file(tokenizer, os.path.join(data_dir, type_path + \".target\"), max_target_length)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Return example as a dictionary containing source_ids, src_mask, and target_ids\n",
    "        source_ids = self.source[index][\"input_ids\"].squeeze() # (1024,)\n",
    "        src_mask = self.source[index][\"attention_mask\"].squeeze()\n",
    "\n",
    "        if self.type_path == \"test\":\n",
    "            return {\"source_ids\": source_ids, \"source_mask\": src_mask}\n",
    "\n",
    "        target_ids = self.target[index][\"input_ids\"].squeeze() # (56, )\n",
    "        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids}\n",
    "\n",
    "    # Static methods, much like class methods, are methods that are bound to a class rather than its object.\n",
    "    # They do not require a class instance creation. So, they are not dependent on the state of the object.\n",
    "    # https://www.programiz.com/python-programming/methods/built-in/staticmethod\n",
    "    @staticmethod\n",
    "    def trim_seq2seq_batch(batch, pad_token_id, test=False):\n",
    "        # Remove columns that are populated exclusively by pad_token_id\n",
    "        # This ensures that each batch is padded only uptil the \"max sequence length\"\n",
    "        # https://github.com/huggingface/transformers/blob/1e51bb717c04ca4b01a05a7a548e6b550be38628/src/transformers/tokenization_utils.py\n",
    "        source_ids, source_mask = trim_batch(batch[\"source_ids\"], pad_token_id, attention_mask=batch[\"source_mask\"])\n",
    "        if test:\n",
    "            return source_ids, source_mask, None\n",
    "        y = trim_batch(batch[\"target_ids\"], pad_token_id)\n",
    "        return source_ids, source_mask, y\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"\n",
    "        The tensors are stacked together as they are yielded.\n",
    "\n",
    "        Collate function is applied to the output of a DataLoader as it is yielded.\n",
    "        \"\"\"\n",
    "        input_ids = torch.stack([x[\"source_ids\"] for x in batch]) # BS x SL\n",
    "        masks = torch.stack([x[\"source_mask\"] for x in batch]) # BS x SL\n",
    "        pad_token_id = self.tokenizer.pad_token_id\n",
    "        source_ids, source_mask = trim_batch(input_ids, pad_token_id, attention_mask=masks)\n",
    "        if self.type_path == \"test\":\n",
    "            return {\"source_ids\": source_ids, \"source_mask\": source_mask}\n",
    "\n",
    "        target_ids = torch.stack([x[\"target_ids\"] for x in batch]) # BS x SL\n",
    "        # Remove columns that are purely padding\n",
    "        y = trim_batch(target_ids, pad_token_id)\n",
    "        # Return dictionary containing tensors\n",
    "        return {\"source_ids\": source_ids, \"source_mask\": source_mask, \"target_ids\": y}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "im8yu0a3JYLt",
    "papermill": {
     "duration": 0.06232,
     "end_time": "2020-11-27T08:05:26.009210",
     "exception": false,
     "start_time": "2020-11-27T08:05:25.946890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model\n",
    "\n",
    "Based on this summarization (encoder-decoder) example from [transformers](https://github.com/huggingface/transformers/blob/master/examples/summarization/bart/finetune.py), which is compatible for both BART and T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:26.175041Z",
     "iopub.status.busy": "2020-11-27T08:05:26.143640Z",
     "iopub.status.idle": "2020-11-27T08:05:26.335367Z",
     "shell.execute_reply": "2020-11-27T08:05:26.334413Z"
    },
    "id": "HM4stMDvJYLt",
    "papermill": {
     "duration": 0.264302,
     "end_time": "2020-11-27T08:05:26.335487",
     "exception": false,
     "start_time": "2020-11-27T08:05:26.071185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModelWithLMHead,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def set_seed(args: argparse.Namespace):\n",
    "    \"\"\"\n",
    "    Set all the seeds to make results replicable\n",
    "    \"\"\"\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "\n",
    "class T5Module(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Base Transformer model that uses Pytorch Lightning as a PyTorch wrapper.\n",
    "\n",
    "    T5 specific methods are implemented in T5Trainer\n",
    "    \"\"\"\n",
    "    def __init__(self, hparams: argparse.Namespace, **config_kwargs):\n",
    "        \"Initialize a model.\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        cache_dir = self.hparams.cache_dir if self.hparams.cache_dir else None\n",
    "        # Read the config file of the T5 model (T5Config)\n",
    "        # AutoConfig allows you to read the configuration for a specified model (e.g. in this case, t5-base)\n",
    "        # Reference: https://huggingface.co/transformers/model_doc/auto.html#autoconfig\n",
    "        self.config = AutoConfig.from_pretrained(self.hparams.model_name_or_path)\n",
    "        # Read the tokenizer of the T5 model (T5Tokenizer)\n",
    "        # AutoTokenizer allows you to read the tokenizer for a specified model (e.g. in this case, t5-base)\n",
    "        # Reference: https://huggingface.co/transformers/model_doc/t5.html#t5tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            self.hparams.model_name_or_path,\n",
    "            cache_dir=cache_dir,\n",
    "        )\n",
    "        # Read the model file for the pre-trained T5 model (T5ForConditionalGeneration)\n",
    "        # AutoModelWithLMHead allows you to read any of the language modelling models from the transformers library (e.g. in this case, t5-base)\n",
    "        # Automodels reference: https://huggingface.co/transformers/model_doc/auto.html#automodel\n",
    "        self.model = AutoModelWithLMHead.from_pretrained(\n",
    "            self.hparams.model_name_or_path,\n",
    "            from_tf=bool(\".ckpt\" in self.hparams.model_name_or_path), # Checkpoint is a TF format\n",
    "            config=self.config,\n",
    "            cache_dir=cache_dir,\n",
    "        )\n",
    "\n",
    "        # Save dataset params\n",
    "        self.dataset_kwargs: dict = dict(\n",
    "            data_dir=self.hparams.data_dir,\n",
    "            max_source_length=self.hparams.max_source_length,\n",
    "            max_target_length=self.hparams.max_target_length,\n",
    "        )\n",
    "\n",
    "    # Forward function\n",
    "    # Defines the forward pass of the module\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids, # Indices of input sequence tokens in the vocabulary. \n",
    "        attention_mask=None, # Mask to avoid performing attention on padding token indices\n",
    "        decoder_input_ids=None, # T5 uses the pad_token_id as the starting token for decoder_input_ids generation.\n",
    "        lm_labels=None # Labels for computing the sequence classification/regression loss (see T5Model). Note: loss is returned when lm_label is provided.\n",
    "        ):\n",
    "        \"\"\"\n",
    "         loss (torch.FloatTensor of shape (1,), optional, returned when lm_label is provided\n",
    "        \"\"\"\n",
    "        # Details on how to use this in the Hugging Face T5 docs: https://huggingface.co/transformers/model_doc/t5.html\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            lm_labels=lm_labels,\n",
    "        )\n",
    "\n",
    "    # Data preparation\n",
    "\n",
    "    def get_dataloader(self, type_path: str, batch_size: int, shuffle: bool = False) -> DataLoader:\n",
    "        dataset = T5Dataset(self.tokenizer, type_path=type_path, **self.dataset_kwargs)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=dataset.collate_fn, shuffle=shuffle)\n",
    "        return dataloader\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        dataloader = self.get_dataloader(\"train\", batch_size=self.hparams.train_batch_size, shuffle=True)\n",
    "        t_total = (\n",
    "            (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
    "            // self.hparams.gradient_accumulation_steps\n",
    "            * float(self.hparams.num_train_epochs)\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n",
    "        )\n",
    "        self.lr_scheduler = scheduler\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return self.get_dataloader(\"val\", batch_size=self.hparams.eval_batch_size)\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return self.get_dataloader(\"test\", batch_size=self.hparams.eval_batch_size)\n",
    "\n",
    "    # Configure optimizers\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "        model = self.model\n",
    "        # Weight decay will not be applied to \"bias\" and \"LayerNorm.weight\" parameters\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "\n",
    "        # Group parameters to those that will and will not have weight decay applied\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.hparams.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        # Use AdamW as an optimizer\n",
    "        # Intro here: https://www.fast.ai/2018/07/02/adam-weight-decay/\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
    "        self.opt = optimizer\n",
    "        return [optimizer]\n",
    "\n",
    "    # Forward pass and calculate loss per batch (step)\n",
    "\n",
    "    def _step(self, batch, return_text=False):\n",
    "        \"\"\"\n",
    "        Runs forward pass and calculates loss per batch. Applied for training_step, and validation_step\n",
    "        \"\"\"\n",
    "        pad_token_id = self.tokenizer.pad_token_id\n",
    "        source_ids, source_mask, y = batch[\"source_ids\"], batch[\"source_mask\"], batch[\"target_ids\"]\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        lm_labels = y[:, 1:].clone()\n",
    "        # Change pad_token_id to -100\n",
    "        lm_labels[y[:, 1:] == pad_token_id] = -100\n",
    "        # Run forward pass and calculate loss\n",
    "        outputs = self(source_ids, attention_mask=source_mask, decoder_input_ids=y_ids, lm_labels=lm_labels,)\n",
    "        # Only get loss from the output since that's all we need to apply our optimizer\n",
    "        loss = outputs[0]\n",
    "        if return_text:\n",
    "            target_text = [self.tokenizer.decode(ids) for ids in y_ids]\n",
    "            return loss, target_text\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "    # Step during training\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Runs forward pass, calculates loss, and returns loss (and logs) in a dict\n",
    "        \"\"\"\n",
    "        loss = self._step(batch)\n",
    "\n",
    "        # Notice that each training step loss is recorded on tensorboard, which makes sense since we're tracking loss per batch\n",
    "        tensorboard_logs = {\"train_loss\": loss}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    # Adjust weights based on calculated gradients and learning rate scheduler\n",
    "\n",
    "    def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None, using_native_amp=None):\n",
    "        \"\"\"\n",
    "        Adjust weights based on calculated gradients + learning rate scheduler, and refresh gradients\n",
    "        Reference for optimizer_step: https://pytorch-lightning.readthedocs.io/en/latest/optimizers.html\n",
    "        \"\"\"\n",
    "        if self.trainer.use_tpu:\n",
    "            xm.optimizer_step(optimizer)\n",
    "        else:\n",
    "            # Adjust weights based on calculated gradients\n",
    "            optimizer.step()\n",
    "\n",
    "        # Refresh gradients (to zero)\n",
    "        optimizer.zero_grad()\n",
    "        # Update the learning rate scheduler\n",
    "        self.lr_scheduler.step()\n",
    "\n",
    "    # Step during validation\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Runs forward pass, calculates loss, and returns loss in a dict\n",
    "        \"\"\"\n",
    "\n",
    "        # Return source and target text to calculate jaccard score only for validation\n",
    "        loss, target_text = self._step(batch, return_text=True)\n",
    "\n",
    "        preds = self.test_step(batch, batch_idx)\n",
    "        preds_text = preds[\"preds\"]\n",
    "        # Track jaccard score to get validation accuracy\n",
    "        jaccard_score = [jaccard(p, t) for p, t in zip(preds_text, target_text)]\n",
    "\n",
    "        return {\"val_loss\": loss, \"jaccard_score\": jaccard_score}\n",
    "\n",
    "    # Show loss after validation\n",
    "\n",
    "    def validation_end(self, outputs):\n",
    "        \"\"\"\n",
    "        Calculate average loss for all the validation batches\n",
    "        \"\"\"\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        jaccard_scores = sum([x[\"jaccard_score\"] for x in outputs], [])\n",
    "        avg_jaccard_score = np.mean(jaccard_scores)\n",
    "        tensorboard_logs = {\"val_loss\": avg_loss, \"jaccard_score\": avg_jaccard_score}\n",
    "        return {\"avg_val_loss\": avg_loss, \"avg_jaccard_score\": avg_jaccard_score, \"log\": tensorboard_logs}\n",
    "\n",
    "    # Step during testing\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Runs forward pass on test set and returns calculated loss, predictions, and targets\n",
    "        Note: this assumes that your test set has targets (doesn't have for kaggle).\n",
    "        \"\"\"\n",
    "        pad_token_id = self.tokenizer.pad_token_id\n",
    "        source_ids, source_mask, _ = T5Dataset.trim_seq2seq_batch(batch, pad_token_id, test=True)\n",
    "        # NOTE: the following kwargs get more speed and lower quality summaries than those in evaluate_cnn.py\n",
    "        # Generate reference: https://github.com/huggingface/transformers/blob/3e0f06210646a440509efa718b30d18322d6a830/src/transformers/modeling_utils.py#L769\n",
    "        # For the sentiment span extraction task, turning off early stopping proved superior\n",
    "        generated_ids = self.model.generate(\n",
    "            input_ids=source_ids,\n",
    "            attention_mask=source_mask,\n",
    "            num_beams=1,\n",
    "            max_length=80,\n",
    "            repetition_penalty=2.5,\n",
    "            length_penalty=1.0,\n",
    "#             early_stopping=True,\n",
    "            use_cache=True,\n",
    "        )\n",
    "        preds = [\n",
    "            self.tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "            for g in generated_ids\n",
    "        ]\n",
    "\n",
    "        return {\"preds\": preds}\n",
    "\n",
    "    # Note: we don't attempt to print the loss from the test set, because it's assumed that we don't have the test targets\n",
    "    def test_end(self, outputs):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        for pred in outputs:\n",
    "            preds += pred[\"preds\"]\n",
    "        return {\"preds\": preds}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        \"\"\"\n",
    "        Save test predictions and targets as text files and return the calculated loss for the test set\n",
    "        \"\"\"\n",
    "        output_test_predictions_file = os.path.join(self.hparams.output_dir, \"test_predictions.txt\")\n",
    "        # write predictions and targets for later rouge evaluation.\n",
    "        with open(output_test_predictions_file, \"w+\") as p_writer:\n",
    "            for output_batch in outputs:\n",
    "                p_writer.writelines(s + \"\\n\" for s in output_batch[\"preds\"])\n",
    "            p_writer.close()\n",
    "\n",
    "        return self.test_end(outputs)\n",
    "\n",
    "    def get_tqdm_dict(self):\n",
    "        \"\"\"\n",
    "        Print average loss and learning rate at each step\n",
    "        \"\"\"\n",
    "        avg_loss = getattr(self.trainer, \"avg_loss\", 0.0)\n",
    "        tqdm_dict = {\"loss\": \"{:.3f}\".format(avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
    "        return tqdm_dict\n",
    "\n",
    "    def _feature_file(self, mode):\n",
    "        return os.path.join(\n",
    "            self.hparams.data_dir,\n",
    "            \"cached_{}_{}_{}\".format(\n",
    "                mode,\n",
    "                list(filter(None, self.hparams.model_name_or_path.split(\"/\"))).pop(),\n",
    "                str(self.hparams.max_seq_length),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def is_logger(self):\n",
    "        return self.trainer.proc_rank <= 0\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parser, root_dir):\n",
    "        parser.add_argument(\n",
    "            \"--model_name_or_path\",\n",
    "            default=None,\n",
    "            type=str,\n",
    "            required=True,\n",
    "            help=\"Path to pretrained model or model identifier from huggingface.co/models\",\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            \"--config_name\", default=\"\", type=str, help=\"Pretrained config name or path if not the same as model_name\"\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            \"--tokenizer_name\",\n",
    "            default=\"\",\n",
    "            type=str,\n",
    "            help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            \"--cache_dir\",\n",
    "            default=\"\",\n",
    "            type=str,\n",
    "            help=\"Where do you want to store the pre-trained models downloaded from s3\",\n",
    "        )\n",
    "        parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
    "        parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\")\n",
    "        parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
    "        parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
    "        parser.add_argument(\n",
    "            \"--num_train_epochs\", default=3, type=int, help=\"Total number of training epochs to perform.\"\n",
    "        )\n",
    "\n",
    "        parser.add_argument(\"--train_batch_size\", default=32, type=int)\n",
    "        parser.add_argument(\"--eval_batch_size\", default=32, type=int)\n",
    "\n",
    "        parser.add_argument(\n",
    "            \"--max_source_length\",\n",
    "            default=1024,\n",
    "            type=int,\n",
    "            help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated, sequences shorter will be padded.\",\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            \"--max_target_length\",\n",
    "            default=56,\n",
    "            type=int,\n",
    "            help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated, sequences shorter will be padded.\",\n",
    "        )\n",
    "\n",
    "        parser.add_argument(\n",
    "            \"--data_dir\",\n",
    "            default=None,\n",
    "            type=str,\n",
    "            required=True,\n",
    "            help=\"The input data dir. Should contain the dataset files for the text generation task.\",\n",
    "        )\n",
    "        return parser\n",
    "\n",
    "\n",
    "class LoggingCallback(pl.Callback):\n",
    "    def on_validation_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule):\n",
    "        logger.info(\"***** Validation results *****\")\n",
    "        if pl_module.is_logger():\n",
    "            metrics = trainer.callback_metrics\n",
    "            # Log results\n",
    "            for key in sorted(metrics):\n",
    "                if key not in [\"log\", \"progress_bar\"]:\n",
    "                    logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "\n",
    "\n",
    "def add_generic_args(parser, root_dir):\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        default=None,\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--fp16\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--fp16_opt_level\",\n",
    "        type=str,\n",
    "        default=\"O1\",\n",
    "        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
    "        \"See details at https://nvidia.github.io/apex/amp.html\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\"--n_gpu\", type=int, default=1)\n",
    "    parser.add_argument(\"--n_tpu_cores\", type=int, default=0)\n",
    "    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n",
    "    parser.add_argument(\"--do_train\", action=\"store_true\", help=\"Whether to run training.\")\n",
    "    parser.add_argument(\"--do_predict\", action=\"store_true\", help=\"Whether to run predictions on the test set.\")\n",
    "    parser.add_argument(\n",
    "        \"--gradient_accumulation_steps\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n",
    "\n",
    "\n",
    "def generic_train(model: T5Module, args: argparse.Namespace):\n",
    "    # init model\n",
    "    set_seed(args)\n",
    "\n",
    "    if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train:\n",
    "        raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(args.output_dir))\n",
    "\n",
    "    # Can take out checkpoint saving after each epoch to save memory\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
    "    )\n",
    "\n",
    "    train_params = dict(\n",
    "        accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "        gpus=args.n_gpu,\n",
    "        max_epochs=args.num_train_epochs,\n",
    "#         early_stop_callback=False,\n",
    "        gradient_clip_val=args.max_grad_norm,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        callbacks=[LoggingCallback()],\n",
    "    )\n",
    "\n",
    "    if args.fp16:\n",
    "        train_params[\"use_amp\"] = args.fp16\n",
    "        train_params[\"amp_level\"] = args.fp16_opt_level\n",
    "\n",
    "    if args.n_tpu_cores > 0:\n",
    "        global xm\n",
    "        import torch_xla.core.xla_model as xm\n",
    "\n",
    "        train_params[\"num_tpu_cores\"] = args.n_tpu_cores\n",
    "        train_params[\"gpus\"] = 0\n",
    "\n",
    "    if args.n_gpu > 1:\n",
    "        train_params[\"distributed_backend\"] = \"ddp\"\n",
    "\n",
    "    trainer = pl.Trainer(**train_params)\n",
    "\n",
    "    if args.do_train:\n",
    "        trainer.fit(model)\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5wgSA-VJYLw",
    "papermill": {
     "duration": 0.062954,
     "end_time": "2020-11-27T08:05:26.461867",
     "exception": false,
     "start_time": "2020-11-27T08:05:26.398913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Finetuning\n",
    "\n",
    "Based on this summarization example from [transformers](https://github.com/huggingface/transformers/blob/master/examples/summarization/bart/finetune.py), which is compatible for both BART and T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:26.606685Z",
     "iopub.status.busy": "2020-11-27T08:05:26.604625Z",
     "iopub.status.idle": "2020-11-27T08:05:26.607422Z",
     "shell.execute_reply": "2020-11-27T08:05:26.607972Z"
    },
    "id": "Q7lrXolxJYLx",
    "papermill": {
     "duration": 0.083226,
     "end_time": "2020-11-27T08:05:26.608117",
     "exception": false,
     "start_time": "2020-11-27T08:05:26.524891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    # If output_dir not provided, a folder will be generated in pwd\n",
    "    if not args.output_dir:\n",
    "        args.output_dir = os.path.join(\"./results\", f\"{args.task}_{time.strftime('%Y%m%d_%H%M%S')}\",)\n",
    "        os.makedirs(args.output_dir)\n",
    "    model = T5Module(args)\n",
    "    trainer = generic_train(model, args)\n",
    "\n",
    "    # Save the last model as model.bin\n",
    "    #checkpoints = list(sorted(glob.glob(os.path.join(args.output_dir, \"checkpointepoch=*.ckpt\"), recursive=True)))\n",
    "    #model = model.load_from_checkpoint(checkpoints[-1])\n",
    "    model.model.save_pretrained(args.output_dir)\n",
    "    # Save tokenizer files\n",
    "    model.tokenizer.save_pretrained('./')\n",
    "    \n",
    "    # Optionally, predict on dev set and write to output_dir\n",
    "    if args.do_predict:\n",
    "        # See https://github.com/huggingface/transformers/issues/3159\n",
    "        # pl use this format to create a checkpoint:\n",
    "        # https://github.com/PyTorchLightning/pytorch-lightning/blob/master\\\n",
    "        # /pytorch_lightning/callbacks/model_checkpoint.py#L169\n",
    "        trainer.test(model)\n",
    "    return trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:26.739524Z",
     "iopub.status.busy": "2020-11-27T08:05:26.738711Z",
     "iopub.status.idle": "2020-11-27T08:05:26.742240Z",
     "shell.execute_reply": "2020-11-27T08:05:26.741619Z"
    },
    "id": "Z99mrA4VJYL3",
    "papermill": {
     "duration": 0.07143,
     "end_time": "2020-11-27T08:05:26.742348",
     "exception": false,
     "start_time": "2020-11-27T08:05:26.670918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!rm -r /content/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:26.875678Z",
     "iopub.status.busy": "2020-11-27T08:05:26.874694Z",
     "iopub.status.idle": "2020-11-27T08:05:27.583314Z",
     "shell.execute_reply": "2020-11-27T08:05:27.582255Z"
    },
    "id": "0_9ICraGJYLz",
    "papermill": {
     "duration": 0.777405,
     "end_time": "2020-11-27T08:05:27.583445",
     "exception": false,
     "start_time": "2020-11-27T08:05:26.806040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:05:27.717376Z",
     "iopub.status.busy": "2020-11-27T08:05:27.716403Z",
     "iopub.status.idle": "2020-11-27T08:12:16.529287Z",
     "shell.execute_reply": "2020-11-27T08:12:16.528569Z"
    },
    "id": "FO2rxaTvJYL5",
    "outputId": "2ad30abd-10c5-4962-cf10-f61cabcfb73a",
    "papermill": {
     "duration": 408.884331,
     "end_time": "2020-11-27T08:12:16.529408",
     "exception": false,
     "start_time": "2020-11-27T08:05:27.645077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8013877a8c4b0daef04806be7b117b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759a695de69b451a9bbee508f889c45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6258c3ef6a497785a37241f3c09935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891691430.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615aca2ddb9642569a7150761acc0a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3472c37c0f3b4099842c4a1307b62a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428398394/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be50fe7533874b448a71153724fcd538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Will set gpu on as soon as at least 1 batch works on cpu\n",
    "# TODO: Consider factors here: https://github.com/huggingface/transformers/issues/3387\n",
    "# Change LR to 1e-3 to 1e-4\n",
    "# \n",
    "ARGS_STR = \"\"\"\n",
    "--data_dir=./ \\\n",
    "--model_name_or_path=t5-base \\\n",
    "--learning_rate=3e-5 \\\n",
    "--train_batch_size=32 \\\n",
    "--output_dir=output/ \\\n",
    "--do_train \\\n",
    "--n_gpu=1 \\\n",
    "--num_train_epochs 1 \\\n",
    "--max_source_length 80 \\\n",
    "\"\"\"\n",
    "#\n",
    "#--eval_batch_size=3 \\\n",
    "#--do_predict \\\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "add_generic_args(parser, os.getcwd())\n",
    "parser = T5Module.add_model_specific_args(parser, os.getcwd())\n",
    "args = parser.parse_args(ARGS_STR.split())\n",
    "trainer = main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.148598,
     "end_time": "2020-11-27T08:12:33.530318",
     "exception": false,
     "start_time": "2020-11-27T08:12:33.381720",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:12:38.046680Z",
     "iopub.status.busy": "2020-11-27T08:12:38.043423Z",
     "iopub.status.idle": "2020-11-27T08:12:38.796311Z",
     "shell.execute_reply": "2020-11-27T08:12:38.795716Z"
    },
    "id": "37xAGCr9tNkF",
    "outputId": "e957f47a-d985-41f4-88bf-313debf7e5f9",
    "papermill": {
     "duration": 1.841004,
     "end_time": "2020-11-27T08:12:38.796437",
     "exception": false,
     "start_time": "2020-11-27T08:12:36.955433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3483128\r\n",
      "-rw-r--r-- 1 root root 2675012593 Nov 27 08:12 'checkpointepoch=0.ckpt'\r\n",
      "-rw-r--r-- 1 root root       1208 Nov 27 08:12  config.json\r\n",
      "-rw-r--r-- 1 root root  891691419 Nov 27 08:12  pytorch_model.bin\r\n"
     ]
    }
   ],
   "source": [
    "ls -l output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:12:39.333379Z",
     "iopub.status.busy": "2020-11-27T08:12:39.332399Z",
     "iopub.status.idle": "2020-11-27T08:12:40.124120Z",
     "shell.execute_reply": "2020-11-27T08:12:40.123452Z"
    },
    "id": "mY2yAR1TsF7E",
    "outputId": "5da05df4-3595-4750-d8eb-e26c75db9a59",
    "papermill": {
     "duration": 1.252451,
     "end_time": "2020-11-27T08:12:40.124250",
     "exception": false,
     "start_time": "2020-11-27T08:12:38.871799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  special_tokens_map.json  tokenizer_config.json  val.source\r\n",
      "\u001b[0m\u001b[01;34mlightning_logs\u001b[0m/     spiece.model             train.source           val.target\r\n",
      "\u001b[01;34moutput\u001b[0m/             test.source              train.target\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:12:40.278447Z",
     "iopub.status.busy": "2020-11-27T08:12:40.277519Z",
     "iopub.status.idle": "2020-11-27T08:12:41.041114Z",
     "shell.execute_reply": "2020-11-27T08:12:41.040031Z"
    },
    "id": "sA1lz-njnSEP",
    "outputId": "a7b10ddf-3e99-487c-b6f3-54a846fa0113",
    "papermill": {
     "duration": 0.843003,
     "end_time": "2020-11-27T08:12:41.041250",
     "exception": false,
     "start_time": "2020-11-27T08:12:40.198247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mversion_0\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:12:41.190298Z",
     "iopub.status.busy": "2020-11-27T08:12:41.189321Z",
     "iopub.status.idle": "2020-11-27T08:12:41.192394Z",
     "shell.execute_reply": "2020-11-27T08:12:41.191858Z"
    },
    "id": "GPO7iVaLcEwA",
    "outputId": "cde1c750-2285-4be6-9b97-4636af287c15",
    "papermill": {
     "duration": 0.079072,
     "end_time": "2020-11-27T08:12:41.192531",
     "exception": false,
     "start_time": "2020-11-27T08:12:41.113459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cat lightning_logs/version_0/hparams.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBK-J-KPJYMI",
    "papermill": {
     "duration": 0.071754,
     "end_time": "2020-11-27T08:12:41.338851",
     "exception": false,
     "start_time": "2020-11-27T08:12:41.267097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Test if saved model works w sample inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:12:41.486051Z",
     "iopub.status.busy": "2020-11-27T08:12:41.485054Z",
     "iopub.status.idle": "2020-11-27T08:12:41.489825Z",
     "shell.execute_reply": "2020-11-27T08:12:41.489174Z"
    },
    "id": "lzZnHlDpJYMI",
    "papermill": {
     "duration": 0.079621,
     "end_time": "2020-11-27T08:12:41.489938",
     "exception": false,
     "start_time": "2020-11-27T08:12:41.410317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:12:41.638488Z",
     "iopub.status.busy": "2020-11-27T08:12:41.637600Z",
     "iopub.status.idle": "2020-11-27T08:12:49.814563Z",
     "shell.execute_reply": "2020-11-27T08:12:49.813328Z"
    },
    "id": "eCHCONzkJYMK",
    "papermill": {
     "duration": 8.252715,
     "end_time": "2020-11-27T08:12:49.814716",
     "exception": false,
     "start_time": "2020-11-27T08:12:41.562001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "t5 = T5ForConditionalGeneration.from_pretrained('output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:12:49.972836Z",
     "iopub.status.busy": "2020-11-27T08:12:49.971762Z",
     "iopub.status.idle": "2020-11-27T08:12:49.974952Z",
     "shell.execute_reply": "2020-11-27T08:12:49.974376Z"
    },
    "id": "oT-Fee2kJYMM",
    "papermill": {
     "duration": 0.084807,
     "end_time": "2020-11-27T08:12:49.975069",
     "exception": false,
     "start_time": "2020-11-27T08:12:49.890262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_span(text):\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\", add_special_tokens=True)  # Batch size 1\n",
    "    t5.eval()\n",
    "    generated_ids = t5.generate(\n",
    "        input_ids=input_ids,\n",
    "        num_beams=1,\n",
    "        max_length=80,\n",
    "        #repetition_penalty=2.5\n",
    "    ).squeeze()\n",
    "    predicted_span = tokenizer.decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return predicted_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:12:50.132905Z",
     "iopub.status.busy": "2020-11-27T08:12:50.132161Z",
     "iopub.status.idle": "2020-11-27T08:12:51.895821Z",
     "shell.execute_reply": "2020-11-27T08:12:51.894807Z"
    },
    "id": "Ny60CpsrJYMP",
    "outputId": "090365a4-6e4f-46b0-a60f-419e8a859c1f",
    "papermill": {
     "duration": 1.846908,
     "end_time": "2020-11-27T08:12:51.895942",
     "exception": false,
     "start_time": "2020-11-27T08:12:50.049034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it makes me kinda sad, he is getting so big, check out my twipics'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_span(\"question: negative context: I`m in VA for the weekend, my youngest son turns 2 tomorrow......it makes me kinda sad, he is getting so big, check out my twipics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:12:52.053284Z",
     "iopub.status.busy": "2020-11-27T08:12:52.051723Z",
     "iopub.status.idle": "2020-11-27T08:12:53.666143Z",
     "shell.execute_reply": "2020-11-27T08:12:53.665216Z"
    },
    "id": "uvQUGSM2JYMU",
    "outputId": "e9d7e555-368a-4271-cd2a-5ac57b0b3bec",
    "papermill": {
     "duration": 1.696576,
     "end_time": "2020-11-27T08:12:53.666310",
     "exception": false,
     "start_time": "2020-11-27T08:12:51.969734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recession hit Veronique Branquinho, she has to quit her company, such a shame!'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_span(\"question: negative context: Recession hit Veronique Branquinho, she has to quit her company, such a shame!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:12:53.827761Z",
     "iopub.status.busy": "2020-11-27T08:12:53.826721Z",
     "iopub.status.idle": "2020-11-27T08:12:54.668398Z",
     "shell.execute_reply": "2020-11-27T08:12:54.669701Z"
    },
    "id": "ngLh3ny0emOv",
    "outputId": "fcc01e51-4edd-4d04-e6fc-033b9bc64f4e",
    "papermill": {
     "duration": 0.929855,
     "end_time": "2020-11-27T08:12:54.669879",
     "exception": false,
     "start_time": "2020-11-27T08:12:53.740024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'argh total bummer'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_span(\"question: negative context: My bike was put on hold...should have known that.... argh total bummer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:12:54.870566Z",
     "iopub.status.busy": "2020-11-27T08:12:54.869037Z",
     "iopub.status.idle": "2020-11-27T08:12:55.338446Z",
     "shell.execute_reply": "2020-11-27T08:12:55.339156Z"
    },
    "id": "uNdqdgowe0zR",
    "outputId": "548dc1d4-63bc-4561-b928-98096aa76e00",
    "papermill": {
     "duration": 0.562418,
     "end_time": "2020-11-27T08:12:55.339314",
     "exception": false,
     "start_time": "2020-11-27T08:12:54.776896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i love you'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_span(\"question: positive context: On the monday, so i wont be able to be with you! i love you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T08:12:55.500617Z",
     "iopub.status.busy": "2020-11-27T08:12:55.499061Z",
     "iopub.status.idle": "2020-11-27T08:12:55.899893Z",
     "shell.execute_reply": "2020-11-27T08:12:55.900421Z"
    },
    "id": "zRVGEpS8emVv",
    "outputId": "44a59d04-4eeb-4379-d56d-93c57dd39216",
    "papermill": {
     "duration": 0.48559,
     "end_time": "2020-11-27T08:12:55.900634",
     "exception": false,
     "start_time": "2020-11-27T08:12:55.415044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'soothing voice.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_span(\"question: positive I liked it. Did you record it yourself? If so you have a very soothing voice.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEQurVqVDYMa",
    "papermill": {
     "duration": 0.075828,
     "end_time": "2020-11-27T08:12:56.051784",
     "exception": false,
     "start_time": "2020-11-27T08:12:55.975956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Key results\n",
    "\n",
    "1. Training T5 with 5 epochs gives an accuracy (Jaccard score) of 0.665\n",
    "  - This is still much lower than the 0.714 at the top 10%\n",
    "  - But, much is yet to be done in terms of post training optimization\n",
    "    - Ensembling, stacking, etc\n",
    "2. The amazing thing for me is the confirmation that a generative model like T5 can perform extractive tasks with an accuracy comparable to a token classification version of BERT\n",
    "\n",
    "I'm confident that T5 can reach leaderboard level results with more experiments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zX-20eSHWgrG",
    "papermill": {
     "duration": 0.074264,
     "end_time": "2020-11-27T08:12:56.200208",
     "exception": false,
     "start_time": "2020-11-27T08:12:56.125944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 496.121833,
   "end_time": "2020-11-27T08:12:57.492321",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-27T08:04:41.370488",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "05582c153f8349999b29349107775359": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "06e82e40a5d84a4e8dd291594b7ce39f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "08b724e393de40149566f28f7865514e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "Validation sanity check: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_30e27aa80e8e4faabfd068ab8c369db4",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f9b4b465c34546139d6b488766f7879d",
       "value": 1
      }
     },
     "11172a251c1f4465ad64c25b15e496ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_59337607ebc14cf0a47a33fa06b8ddab",
       "max": 791656,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b944d5e7e71942caaab4a5535f268719",
       "value": 791656
      }
     },
     "11658fcc393b4076abcddaeeab037070": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cb9522f5bb334497b1633794c940be4b",
       "placeholder": "​",
       "style": "IPY_MODEL_5fef70e4170b455f9ac5e65a2732e8b8",
       "value": " 792k/792k [00:00&lt;00:00, 2.86MB/s]"
      }
     },
     "1340a2c20c604706b228c89b6acf680e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "181611d90ae64b50af7e70a8780e2416": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_384798056b5f4617b71be246057a0c98",
       "max": 891691430,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_80dca4b439c345e29ae0465c6284aeb9",
       "value": 891691430
      }
     },
     "1b8013877a8c4b0daef04806be7b117b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9023614b009446a7badbfdfa5cb3278e",
        "IPY_MODEL_67d4dde65e994ee58b96612368561b98"
       ],
       "layout": "IPY_MODEL_984f9c1e23cc4a1fbb5cfb42f196446d"
      }
     },
     "1d983e828d8a4db5918b275cf93e0856": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "1f78072ef3124b44b85d2b5351c04a61": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "27784b4a2ab9451c9cdaca419984efa4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "279cc2e1d15f4d7bb17296d37c582ffe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "29dee06fc5d04fcebb8d0c206453665f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "30e27aa80e8e4faabfd068ab8c369db4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3472c37c0f3b4099842c4a1307b62a2d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e0a7f1dcde3e484b98b39b6e7081781e",
        "IPY_MODEL_c10ba327adb2436d8cc434741f0cc049"
       ],
       "layout": "IPY_MODEL_1d983e828d8a4db5918b275cf93e0856"
      }
     },
     "384798056b5f4617b71be246057a0c98": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "39b35b624f414e32bb53cb58474e7be7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1340a2c20c604706b228c89b6acf680e",
       "placeholder": "​",
       "style": "IPY_MODEL_e64c4c026ca140c1b8ec3fb803ca6eb1",
       "value": " 1/1.0 [00:04&lt;00:00,  4.19s/it]"
      }
     },
     "59337607ebc14cf0a47a33fa06b8ddab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5fef70e4170b455f9ac5e65a2732e8b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "615aca2ddb9642569a7150761acc0a9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_08b724e393de40149566f28f7865514e",
        "IPY_MODEL_39b35b624f414e32bb53cb58474e7be7"
       ],
       "layout": "IPY_MODEL_279cc2e1d15f4d7bb17296d37c582ffe"
      }
     },
     "6338602179644177802cee718af4cf97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "67d4dde65e994ee58b96612368561b98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_06e82e40a5d84a4e8dd291594b7ce39f",
       "placeholder": "​",
       "style": "IPY_MODEL_8a13015904be4e35bfd9f7df9179921e",
       "value": " 1.20k/1.20k [00:36&lt;00:00, 32.5B/s]"
      }
     },
     "759a695de69b451a9bbee508f889c45c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_11172a251c1f4465ad64c25b15e496ae",
        "IPY_MODEL_11658fcc393b4076abcddaeeab037070"
       ],
       "layout": "IPY_MODEL_9410c85bf161424e920700866402a481"
      }
     },
     "77690b8d66f54df4bb5416756c78d015": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "80dca4b439c345e29ae0465c6284aeb9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "8a13015904be4e35bfd9f7df9179921e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9023614b009446a7badbfdfa5cb3278e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cb31205f9c7944a882edbef567b25755",
       "max": 1199,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1f78072ef3124b44b85d2b5351c04a61",
       "value": 1199
      }
     },
     "9410c85bf161424e920700866402a481": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "97654b04ccdf44a0907cf405b8da73b2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "984f9c1e23cc4a1fbb5cfb42f196446d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b6f9ebaf3e8c4255999213b5ebb05880": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b944d5e7e71942caaab4a5535f268719": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "be50fe7533874b448a71153724fcd538": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fd96749978fa4865800bd38ebeeab642",
        "IPY_MODEL_bef011268dae4b47ba00204e5de26568"
       ],
       "layout": "IPY_MODEL_05582c153f8349999b29349107775359"
      }
     },
     "bef011268dae4b47ba00204e5de26568": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_97654b04ccdf44a0907cf405b8da73b2",
       "placeholder": "​",
       "style": "IPY_MODEL_b6f9ebaf3e8c4255999213b5ebb05880",
       "value": " 16/16 [00:35&lt;00:00,  1.72s/it]"
      }
     },
     "c10ba327adb2436d8cc434741f0cc049": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e558f97652ef47afa903f9f31e815515",
       "placeholder": "​",
       "style": "IPY_MODEL_29dee06fc5d04fcebb8d0c206453665f",
       "value": " 764/764 [05:44&lt;00:00,  2.22it/s, loss=0.206, v_num=0]"
      }
     },
     "c64ec27f3c8c409a9cdd988877bc9f07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c9c4a75f957c4c64bf487a8cb12c26be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "cb31205f9c7944a882edbef567b25755": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cb9522f5bb334497b1633794c940be4b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d5721b7f29ef4740965cc1fb559073f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e3a157d5e2ac4be88d99eea0f68662fc",
       "placeholder": "​",
       "style": "IPY_MODEL_c64ec27f3c8c409a9cdd988877bc9f07",
       "value": " 892M/892M [00:30&lt;00:00, 29.7MB/s]"
      }
     },
     "df65ab505ef54ed58d70557246397a37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e0a7f1dcde3e484b98b39b6e7081781e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Epoch 0: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6338602179644177802cee718af4cf97",
       "max": 764,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c9c4a75f957c4c64bf487a8cb12c26be",
       "value": 764
      }
     },
     "e3a157d5e2ac4be88d99eea0f68662fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e558f97652ef47afa903f9f31e815515": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e64c4c026ca140c1b8ec3fb803ca6eb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ea6258c3ef6a497785a37241f3c09935": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_181611d90ae64b50af7e70a8780e2416",
        "IPY_MODEL_d5721b7f29ef4740965cc1fb559073f6"
       ],
       "layout": "IPY_MODEL_77690b8d66f54df4bb5416756c78d015"
      }
     },
     "f9b4b465c34546139d6b488766f7879d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "fd96749978fa4865800bd38ebeeab642": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "Validating: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_df65ab505ef54ed58d70557246397a37",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_27784b4a2ab9451c9cdaca419984efa4",
       "value": 1
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
